{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Going Deeper(NLP)_YJ2  4. 뉴스 카테고리 다중분류",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XpUzVR6Q4dis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.데이터 로드"
      ],
      "metadata": {
        "id": "o74Nbxcf4hDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "\n"
      ],
      "metadata": {
        "id": "ZwEe5yKw4jsq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 빈도수 상위 5,000개의 단어만 사용\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=5000, test_split=0.2)"
      ],
      "metadata": {
        "id": "dWaZJqVc4sYE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
        "print('테스트 샘플의 수: {}'.format(len(x_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjjQPWQa56ol",
        "outputId": "c2366d90-daf3-438e-a4f5-a6605f1c769f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 샘플의 수: 8982\n",
            "테스트 샘플의 수: 2246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 출력해보기"
      ],
      "metadata": {
        "id": "shPffSFS6IIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[0])\n",
        "print(x_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzvjUrui6JGL",
        "outputId": "830fc74d-caf9-4994-c7b2-6adea3fa94ba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
            "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 2, 159, 9, 1084, 363, 13, 2, 71, 9, 2, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 2, 7, 748, 48, 9, 2, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[0])\n",
        "print(y_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smL5c1qf6Lnp",
        "outputId": "250797a4-8591-41a9-8776-2f1cc466e6a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = max(y_train) + 1\n",
        "print('클래스의 수 : {}'.format(num_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUsC6VT86U2n",
        "outputId": "cae34ce9-2367-463a-e290-9b97f1382fa2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "클래스의 수 : 46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 분포 확인"
      ],
      "metadata": {
        "id": "Hg-T8VRw6lNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련용 뉴스의 최대 길이 :{}'.format(max(len(l) for l in x_train)))\n",
        "print('훈련용 뉴스의 평균 길이 :{}'.format(sum(map(len, x_train))/len(x_train)))\n",
        "\n",
        "plt.hist([len(s) for s in x_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "_dUNfzGA6mfH",
        "outputId": "cd18c3b5-6e16-4b67-9a46-af78d7938202"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련용 뉴스의 최대 길이 :2376\n",
            "훈련용 뉴스의 평균 길이 :145.5398574927633\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axe = plt.subplots(ncols=1)\n",
        "fig.set_size_inches(11,5)\n",
        "sns.countplot(x=y_train)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "lr69Elr56uI_",
        "outputId": "ea3afd00-3c7e-476e-d07a-12e7e01f3e9c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 792x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
        "print(\"각 클래스 빈도수:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrZIqT_96zqq",
        "outputId": "d62f345d-4764-4ba2-9e80-390184a7c0e0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 클래스 빈도수:\n",
            "[[   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
            "    14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
            "    28   29   30   31   32   33   34   35   36   37   38   39   40   41\n",
            "    42   43   44   45]\n",
            " [  55  432   74 3159 1949   17   48   16  139  101  124  390   49  172\n",
            "    26   20  444   39   66  549  269  100   15   41   62   92   24   15\n",
            "    48   19   45   39   32   11   50   10   49   19   19   24   36   30\n",
            "    13   21   12   18]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 복원하기"
      ],
      "metadata": {
        "id": "Ujmadoye64TX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "590QxL3L645S",
        "outputId": "f6145c87-c63f-4cde-ff6c-cd75aa1dbd82"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 0us/step\n",
            "565248/550378 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word = { index+3 : word for word, index in word_index.items() }"
      ],
      "metadata": {
        "id": "ESZKspO-7BGh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
        "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
        "  index_to_word[index]=token"
      ],
      "metadata": {
        "id": "KVRR9PzL7PbT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(' '.join([index_to_word[index] for index in x_train[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9MpHC_f7bZt",
        "outputId": "029437be-70c6-4fa5-d422-a4a8344d4087"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(' '.join([index_to_word[index] for index in [4, 587, 23, 133, 6, 30, 515]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYk0DCWO7cIK",
        "outputId": "245c94f5-07cd-4b75-ce7b-8c261ed7ff80"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the transaction is expected to be completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 텍스트 데이터로 변환"
      ],
      "metadata": {
        "id": "eavPvJSB7fgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoded = []\n",
        "for i in range(len(x_train)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
        "    decoded.append(t)\n",
        "\n",
        "x_train = decoded\n",
        "print(len(x_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3ikz0ya7gSi",
        "outputId": "b168cd02-6f3d-47c4-c0b4-8ffe7653789e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded = []\n",
        "for i in range(len(x_test)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
        "    decoded.append(t)\n",
        "\n",
        "x_test = decoded\n",
        "print(len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5YwCid99Bjc",
        "outputId": "fff637c4-4be9-4e60-9a0c-40df7681c099"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi56Ydng9EC6",
        "outputId": "ca736f77-66b5-4829-8f9f-2f82754a0d4c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3',\n",
              " '<sos> generale de banque sa lt <unk> <unk> and lt heller overseas corp of chicago have each taken 50 pct stakes in <unk> company sa <unk> factors generale de banque said in a statement it gave no financial details of the transaction sa <unk> <unk> turnover in 1986 was 17 5 billion belgian francs reuter 3',\n",
              " '<sos> shr 3 28 dlrs vs 22 cts shr diluted 2 99 dlrs vs 22 cts net 46 0 mln vs 3 328 000 avg shrs 14 0 mln vs 15 2 mln year shr 5 41 dlrs vs 1 56 dlrs shr diluted 4 94 dlrs vs 1 50 dlrs net 78 2 mln vs 25 9 mln avg shrs 14 5 mln vs 15 1 mln note earnings per share reflect the two for one split effective january 6 1987 per share amounts are calculated after preferred stock dividends loss continuing operations for the qtr 1986 includes gains of sale of investments in <unk> corp of 14 mln dlrs and associated companies of 4 189 000 less writedowns of investments in national <unk> inc of 11 8 mln and <unk> corp of 15 6 mln reuter 3',\n",
              " \"<sos> the farmers home administration the u s agriculture department's farm lending arm could lose about seven billion dlrs in outstanding principal on its severely <unk> borrowers or about one fourth of its farm loan portfolio the general accounting office gao said in remarks prepared for delivery to the senate agriculture committee brian <unk> senior associate director of gao also said that a preliminary analysis of proposed changes in <unk> financial <unk> standards indicated as many as one half of <unk> borrowers who received new loans from the agency in 1986 would be <unk> under the proposed system the agency has proposed <unk> <unk> credit using a variety of financial <unk> instead of <unk> <unk> on <unk> ability senate agriculture committee chairman <unk> <unk> d <unk> <unk> the proposed <unk> changes telling <unk> administrator <unk> clark at a hearing that they would mark a dramatic shift in the <unk> purpose away from being <unk> <unk> of last <unk> toward becoming a big city bank but clark <unk> the new regulations saying the agency had a responsibility to <unk> its 70 billion dlr loan portfolio in a <unk> yet <unk> manner <unk> of gao <unk> <unk> arm said the proposed credit <unk> system attempted to ensure that <unk> would make loans only to borrowers who had a reasonable change of <unk> their debt reuter 3\",\n",
              " '<sos> <unk> co said its board has received a proposal from chairman and chief executive officer philip d <unk> to acquire <unk> for 15 75 dlrs per share in cash <unk> said the acquisition bid is subject to <unk> arranging the necessary financing it said he intends to ask other members of senior management to participate the company said <unk> owns 30 pct of <unk> stock and other management members another 7 5 pct <unk> said it has formed an independent board committee to consider the offer and has deferred the annual meeting it had scheduled for march 31 reuter 3']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M79fUNEM9Hsb",
        "outputId": "b524bf0c-59f7-47cc-8593-b7efbd1c4341"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos> the great atlantic and pacific tea co said its three year 345 mln dlr capital program will be be substantially increased to <unk> growth and expansion plans for <unk> inc and <unk> inc over the next two years a and p said the acquisition of <unk> in august 1986 and <unk> in december helped us achieve better than expected results in the fourth quarter ended february 28 its net income from continuing operations jumped 52 6 pct to 20 7 mln dlrs or 55 cts a share in the latest quarter as sales increased 48 3 pct to 1 58 billion dlrs a and p gave no details on the expanded capital program but it did say it completed the first year of the program during 1986 a and p is 52 4 pct owned by lt <unk> <unk> of west germany reuter 3',\n",
              " \"<sos> philippine sugar production in the 1987 88 crop year ending august has been set at 1 6 mln tonnes up from a provisional 1 3 mln tonnes this year sugar regulatory administration <unk> chairman <unk> <unk> said <unk> told reuters a survey during the current milling season which ends next month showed the 1986 87 estimate would almost certainly be met he said at least 1 2 mln tonnes of the 1987 88 crop would be <unk> for domestic consumption <unk> said about 130 000 tonnes would be set aside for the u s sugar quota 150 000 tonnes for strategic reserves and 50 000 tonnes would be sold on the world market he said if the government approved a long standing <unk> recommendation to manufacture <unk> the project would take up another 150 000 tonnes slightly raising the target the government for its own reasons has been <unk> approval of the project but we expect it to come through by july <unk> said <unk> could make up five pct of gasoline cutting the oil import bill by about 300 mln pesos <unk> said three major philippine <unk> were ready to start manufacturing <unk> if the project was approved the <unk> project would result in employment for about 100 000 people sharply reducing those <unk> out of work by depressed world sugar prices and a <unk> domestic industry production quotas set for the first time in 1987 88 had been submitted to president <unk> <unk> i think the president would rather wait <unk> the new congress <unk> after the may elections he said but there is really no need for such quotas we are right now producing just slightly over our own consumption level the producers have never <unk> such high prices <unk> said adding sugar was currently selling <unk> for 320 pesos per <unk> up from 190 pesos last august <unk> said prices were <unk> up because of speculation following the <unk> bid to control production we are no longer concerned so much with the world market he said adding producers in the <unk> region had <unk> from their <unk> and diversified into corn and <unk> <unk> and <unk> production he said <unk> into products other than <unk> was also possible within the sugar industry the <unk> long ago <unk> their <unk> <unk> said they have 300 sugar mills compared with our 41 but they <unk> many of them and diversified production we want to call this a <unk> <unk> instead of the sugar industry he said <unk> could be fed to <unk> and livestock used for <unk> <unk> or used in room <unk> when you cut <unk> you don't even have to produce sugar he said <unk> said the philippines was <unk> for a renewal of the international sugar agreement which expired in 1984 as a major sugar producer we are urging them to write a new agreement which would <unk> world prices <unk> said if there is no agreement world prices will always be depressed particularly because the european community is <unk> its producers and dumping sugar on the markets he said current world prices holding steady at about 7 60 cents per pound were <unk> for the philippines where production costs ranged from 12 to 14 cents a pound if the price holds steady for a while at 7 60 cents i expect the level to rise to about 11 cents a pound by the end of this year he said <unk> said economists forecast a bullish sugar market by 1990 with world consumption <unk> production he said sugar markets were holding up despite <unk> from <unk> <unk> and high <unk> corn <unk> but we are not happy with the reagan administration he said since <unk> we have been regular suppliers of sugar to the u s in 1982 when they restored the quota system they cut <unk> in half without any <unk> <unk> was <unk> <unk> washington's moves to cut domestic support prices to 12 cents a pound from 18 cents the u s agriculture department last december <unk> its 12 month 1987 sugar import quota from the philippines to 143 780 short tons from 231 660 short tons in 1986 <unk> said despite next year's increased production target some philippine mills were expected to shut down at least four of the 41 mills were not working during the 1986 87 season he said we expect two or three more to follow suit during the next season reuter 3\",\n",
              " \"<sos> the agriculture department's widening of louisiana gulf differentials will affect county posted prices for number two <unk> corn in ten states a usda official said all <unk> in iowa will be affected as will <unk> which use the gulf to price corn in illinois indiana <unk> <unk> missouri mississippi <unk> <unk> and louisiana said <unk> <unk> deputy director of commodity operations division for the usda usda last night <unk> the grain industry that effective immediately all gulf differentials used to price interior corn would be widened on a <unk> scale basis of four to eight cts depending on what the differential is usda's action was taken to lower <unk> high posted county prices for corn caused by high gulf prices we've been following this louisiana gulf situation for a month and we don't think it's going to get back in line in any nearby time <unk> said <unk> said usda will probably narrow back the gulf differentials when and if gulf prices <unk> if we're off the mark now because we're too high <unk> we be as much off the mark if we're too low he said while forecasting more adjustments if gulf prices fall <unk> said no other changes in usda's price system are being planned right now we don't <unk> we don't make changes <unk> and we don't make changes often he said reuter 3\",\n",
              " '<sos> <unk> <unk> oil and gas partnership said it completed the sale of interests in two major oil and gas fields to lt energy assets international corp for 21 mln dlrs the company said it sold about one half of its 50 pct interest in the <unk> hill and north <unk> fields its two largest producing properties it said it used about 20 mln dlrs of the proceeds to <unk> principal on its senior secured notes semi annual principal payments on the remaining 40 mln dlrs of notes have been satisfied until december 1988 as a result it said the company said the note agreements were amended to reflect an easing of some financial <unk> and an increase of interest to 13 5 pct from 13 0 pct until december 1990 it said the <unk> exercise price for 1 125 000 warrants was also reduced to 50 cts from 1 50 dlrs the company said energy assets agreed to share the costs of increasing production at the <unk> hill field reuter 3',\n",
              " '<sos> strong south <unk> winds were keeping many vessels <unk> in the ice off the <unk> and swedish <unk> in one of the worst <unk> periods in the baltic for many years the <unk> board of navigation said in <unk> and sweden up to 50 vessels were reported to be <unk> in the ice and even the largest of the <unk> <unk> were having difficulties in breaking through to the <unk> ships <unk> officials said however <unk> conditions in the southern baltic at the soviet oil ports of <unk> and <unk> had eased they said weather officials in <unk> sweden said the <unk> conditions in the baltic were the worst for 30 years with ships fighting a losing battle to keep moving in the coastal <unk> of the gulf of <unk> which <unk> <unk> and sweden the ice is up to one <unk> <unk> with <unk> and <unk> <unk> it into almost <unk> <unk> three metres high swedish <unk> officials said weather forecasts say winds may ease during the weekend but a further drop in <unk> could bring shipping to a standstill the officials said reuter 3']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "벡터화 하기"
      ],
      "metadata": {
        "id": "QTggmBJa9KRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ],
      "metadata": {
        "id": "9Zz8PqRy9LTv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtmvector = CountVectorizer() \n",
        "x_train_dtm = dtmvector.fit_transform(x_train)\n",
        "print(x_train_dtm.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_fo_zCL9hz0",
        "outputId": "ba5a44b0-db2a-4748-dbab-bc3cfd444b72"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8982, 4867)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
        "print(tfidfv.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3spFaawy9pMj",
        "outputId": "42db0e8b-aa98-45f0-b2f1-531b6eb50a7b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8982, 4867)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    사용할 모델\n",
        "\n",
        "    나이브 베이즈 분류기, CNB, 로지스틱 회귀, 서포트 벡터 머신, 결정 트리, 랜덤 포레스트, 그래디언트 부스팅 트리, 보팅 "
      ],
      "metadata": {
        "id": "LBRcWkYd96xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB #다항분포 나이브 베이즈 모델\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score #정확도 계산"
      ],
      "metadata": {
        "id": "-6RuvCQN98d5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print('=3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8fwsj57yhBZ",
        "outputId": "dfb47df6-ee95-4ed7-d44c-45261e2b0bb4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 나이브 베이즈 분류기"
      ],
      "metadata": {
        "id": "eGjGBpDT-TLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultinomialNB()\n",
        "model.fit(tfidfv, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swgMTSEJ-TsT",
        "outputId": "3578c8d3-5593-450e-9494-93191fbbf12a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
        "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환\n",
        "\n",
        "predicted = model.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
        "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6haBJut-XjX",
        "outputId": "c674d40a-330a-4ec4-acb3-cbc2d2146c57"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.6731967943009796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, model.predict(tfidfv_test), zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zIyKySjBqXX",
        "outputId": "9f20fb9e-5da6-4d5a-c02d-f653a2aa8ac0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        12\n",
            "           1       0.50      0.80      0.62       105\n",
            "           2       0.00      0.00      0.00        20\n",
            "           3       0.86      0.89      0.87       813\n",
            "           4       0.59      0.95      0.73       474\n",
            "           5       0.00      0.00      0.00         5\n",
            "           6       0.00      0.00      0.00        14\n",
            "           7       0.00      0.00      0.00         3\n",
            "           8       0.00      0.00      0.00        38\n",
            "           9       1.00      0.28      0.44        25\n",
            "          10       0.00      0.00      0.00        30\n",
            "          11       0.48      0.73      0.58        83\n",
            "          12       0.00      0.00      0.00        13\n",
            "          13       1.00      0.14      0.24        37\n",
            "          14       0.00      0.00      0.00         2\n",
            "          15       0.00      0.00      0.00         9\n",
            "          16       0.60      0.66      0.62        99\n",
            "          17       0.00      0.00      0.00        12\n",
            "          18       0.00      0.00      0.00        20\n",
            "          19       0.51      0.81      0.63       133\n",
            "          20       0.90      0.13      0.23        70\n",
            "          21       0.00      0.00      0.00        27\n",
            "          22       0.00      0.00      0.00         7\n",
            "          23       0.00      0.00      0.00        12\n",
            "          24       0.00      0.00      0.00        19\n",
            "          25       1.00      0.06      0.12        31\n",
            "          26       0.00      0.00      0.00         8\n",
            "          27       0.00      0.00      0.00         4\n",
            "          28       0.00      0.00      0.00        10\n",
            "          29       0.00      0.00      0.00         4\n",
            "          30       0.00      0.00      0.00        12\n",
            "          31       0.00      0.00      0.00        13\n",
            "          32       0.00      0.00      0.00        10\n",
            "          33       0.00      0.00      0.00         5\n",
            "          34       0.00      0.00      0.00         7\n",
            "          35       0.00      0.00      0.00         6\n",
            "          36       0.00      0.00      0.00        11\n",
            "          37       0.00      0.00      0.00         2\n",
            "          38       0.00      0.00      0.00         3\n",
            "          39       0.00      0.00      0.00         5\n",
            "          40       0.00      0.00      0.00        10\n",
            "          41       0.00      0.00      0.00         8\n",
            "          42       0.00      0.00      0.00         3\n",
            "          43       0.00      0.00      0.00         6\n",
            "          44       0.00      0.00      0.00         5\n",
            "          45       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.67      2246\n",
            "   macro avg       0.16      0.12      0.11      2246\n",
            "weighted avg       0.60      0.67      0.60      2246\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "컴플리먼트 나이브 베이즈 분류기(CNB)"
      ],
      "metadata": {
        "id": "QUtgmGizCUwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cb = ComplementNB()\n",
        "cb.fit(tfidfv, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojGbvZRHCUYO",
        "outputId": "a38e55a9-55dc-4a22-e676-923903e5427a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ComplementNB()"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
        "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUjeKFLnCZoU",
        "outputId": "a32a7805-3d81-4805-d50b-4e57bb2e8ce6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.7707034728406055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, cb.predict(tfidfv_test), zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7tXTBgrCcA-",
        "outputId": "67824443-9c05-46d0-b56d-e29c1c0ca2da"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.58      0.70        12\n",
            "           1       0.63      0.86      0.73       105\n",
            "           2       0.91      0.50      0.65        20\n",
            "           3       0.91      0.89      0.90       813\n",
            "           4       0.74      0.92      0.82       474\n",
            "           5       0.00      0.00      0.00         5\n",
            "           6       0.86      0.86      0.86        14\n",
            "           7       1.00      0.67      0.80         3\n",
            "           8       0.57      0.21      0.31        38\n",
            "           9       0.82      0.92      0.87        25\n",
            "          10       0.96      0.80      0.87        30\n",
            "          11       0.54      0.76      0.63        83\n",
            "          12       0.00      0.00      0.00        13\n",
            "          13       0.69      0.59      0.64        37\n",
            "          14       0.00      0.00      0.00         2\n",
            "          15       0.00      0.00      0.00         9\n",
            "          16       0.67      0.79      0.72        99\n",
            "          17       0.00      0.00      0.00        12\n",
            "          18       0.55      0.60      0.57        20\n",
            "          19       0.56      0.80      0.66       133\n",
            "          20       0.79      0.33      0.46        70\n",
            "          21       0.78      0.67      0.72        27\n",
            "          22       0.00      0.00      0.00         7\n",
            "          23       0.67      0.33      0.44        12\n",
            "          24       0.67      0.11      0.18        19\n",
            "          25       0.86      0.77      0.81        31\n",
            "          26       0.88      0.88      0.88         8\n",
            "          27       1.00      0.25      0.40         4\n",
            "          28       0.33      0.20      0.25        10\n",
            "          29       0.00      0.00      0.00         4\n",
            "          30       0.00      0.00      0.00        12\n",
            "          31       1.00      0.15      0.27        13\n",
            "          32       1.00      0.70      0.82        10\n",
            "          33       1.00      0.80      0.89         5\n",
            "          34       1.00      0.71      0.83         7\n",
            "          35       1.00      0.17      0.29         6\n",
            "          36       0.00      0.00      0.00        11\n",
            "          37       1.00      0.50      0.67         2\n",
            "          38       1.00      0.33      0.50         3\n",
            "          39       0.00      0.00      0.00         5\n",
            "          40       0.00      0.00      0.00        10\n",
            "          41       0.67      0.25      0.36         8\n",
            "          42       1.00      0.33      0.50         3\n",
            "          43       1.00      0.17      0.29         6\n",
            "          44       1.00      0.80      0.89         5\n",
            "          45       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.77      2246\n",
            "   macro avg       0.63      0.44      0.48      2246\n",
            "weighted avg       0.76      0.77      0.75      2246\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "로지스틱 회귀"
      ],
      "metadata": {
        "id": "cdCFdgUfCxra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(C=10000, penalty='l2')\n",
        "lr.fit(tfidfv, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjOEy-88CwfA",
        "outputId": "d97cf2fe-0603-42cb-bace-c8a078af6ac8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=10000)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
        "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNNw73WHDBT_",
        "outputId": "fb294da6-9ab0-4912-c17a-29385a45cf78"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.8058771148708815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, lr.predict(tfidfv_test), zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_buKTAu9DKRF",
        "outputId": "d0673d93-8fdb-4165-ecf0-88db7b47656f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.67      0.76        12\n",
            "           1       0.77      0.80      0.79       105\n",
            "           2       0.74      0.85      0.79        20\n",
            "           3       0.91      0.93      0.92       813\n",
            "           4       0.81      0.87      0.84       474\n",
            "           5       0.00      0.00      0.00         5\n",
            "           6       0.92      0.86      0.89        14\n",
            "           7       1.00      0.67      0.80         3\n",
            "           8       0.64      0.74      0.68        38\n",
            "           9       0.81      0.88      0.85        25\n",
            "          10       0.93      0.87      0.90        30\n",
            "          11       0.64      0.73      0.68        83\n",
            "          12       0.57      0.31      0.40        13\n",
            "          13       0.64      0.62      0.63        37\n",
            "          14       0.50      0.50      0.50         2\n",
            "          15       0.83      0.56      0.67         9\n",
            "          16       0.67      0.73      0.70        99\n",
            "          17       0.82      0.75      0.78        12\n",
            "          18       0.80      0.60      0.69        20\n",
            "          19       0.66      0.68      0.67       133\n",
            "          20       0.61      0.47      0.53        70\n",
            "          21       0.62      0.78      0.69        27\n",
            "          22       0.00      0.00      0.00         7\n",
            "          23       0.55      0.50      0.52        12\n",
            "          24       0.69      0.58      0.63        19\n",
            "          25       0.91      0.65      0.75        31\n",
            "          26       1.00      0.88      0.93         8\n",
            "          27       1.00      0.25      0.40         4\n",
            "          28       0.67      0.40      0.50        10\n",
            "          29       0.50      0.75      0.60         4\n",
            "          30       1.00      0.42      0.59        12\n",
            "          31       0.70      0.54      0.61        13\n",
            "          32       1.00      0.80      0.89        10\n",
            "          33       0.80      0.80      0.80         5\n",
            "          34       1.00      0.29      0.44         7\n",
            "          35       1.00      0.33      0.50         6\n",
            "          36       0.38      0.27      0.32        11\n",
            "          37       0.50      0.50      0.50         2\n",
            "          38       0.50      0.33      0.40         3\n",
            "          39       0.40      0.40      0.40         5\n",
            "          40       0.75      0.30      0.43        10\n",
            "          41       0.83      0.62      0.71         8\n",
            "          42       1.00      0.67      0.80         3\n",
            "          43       0.67      1.00      0.80         6\n",
            "          44       1.00      0.80      0.89         5\n",
            "          45       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.81      2246\n",
            "   macro avg       0.73      0.61      0.64      2246\n",
            "weighted avg       0.80      0.81      0.80      2246\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "서포트 벡터 머신"
      ],
      "metadata": {
        "id": "OEGwGtRyDcD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
        "lsvc.fit(tfidfv, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvxyP-JqDcdC",
        "outputId": "eeb14944-cfc1-4cf1-baed-f115fbc7f903"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1000, dual=False, max_iter=500, penalty='l1')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
        "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LN9l6iQDhl_",
        "outputId": "ff39fc6e-5dd2-4923-faa6-e6a00e2e245f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.7702582368655387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, lsvc.predict(tfidfv_test), zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqGRk77ZE1q2",
        "outputId": "765ccca6-8232-4147-e19e-da3ab1dc0c79"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.67      0.76        12\n",
            "           1       0.70      0.72      0.71       105\n",
            "           2       0.79      0.75      0.77        20\n",
            "           3       0.90      0.90      0.90       813\n",
            "           4       0.79      0.85      0.82       474\n",
            "           5       0.00      0.00      0.00         5\n",
            "           6       0.76      0.93      0.84        14\n",
            "           7       1.00      0.33      0.50         3\n",
            "           8       0.68      0.66      0.67        38\n",
            "           9       0.80      0.80      0.80        25\n",
            "          10       0.76      0.73      0.75        30\n",
            "          11       0.61      0.71      0.66        83\n",
            "          12       0.36      0.31      0.33        13\n",
            "          13       0.51      0.57      0.54        37\n",
            "          14       1.00      0.50      0.67         2\n",
            "          15       0.50      0.22      0.31         9\n",
            "          16       0.65      0.69      0.67        99\n",
            "          17       0.60      0.25      0.35        12\n",
            "          18       0.85      0.55      0.67        20\n",
            "          19       0.63      0.68      0.65       133\n",
            "          20       0.54      0.50      0.52        70\n",
            "          21       0.56      0.70      0.62        27\n",
            "          22       1.00      0.14      0.25         7\n",
            "          23       0.40      0.50      0.44        12\n",
            "          24       0.64      0.47      0.55        19\n",
            "          25       0.83      0.61      0.70        31\n",
            "          26       1.00      0.75      0.86         8\n",
            "          27       0.67      0.50      0.57         4\n",
            "          28       0.20      0.20      0.20        10\n",
            "          29       0.50      0.75      0.60         4\n",
            "          30       0.75      0.25      0.38        12\n",
            "          31       0.82      0.69      0.75        13\n",
            "          32       0.88      0.70      0.78        10\n",
            "          33       0.67      0.80      0.73         5\n",
            "          34       0.50      0.57      0.53         7\n",
            "          35       1.00      0.33      0.50         6\n",
            "          36       0.62      0.45      0.53        11\n",
            "          37       0.50      1.00      0.67         2\n",
            "          38       1.00      0.33      0.50         3\n",
            "          39       0.50      0.20      0.29         5\n",
            "          40       0.50      0.20      0.29        10\n",
            "          41       0.67      0.50      0.57         8\n",
            "          42       1.00      0.33      0.50         3\n",
            "          43       0.86      1.00      0.92         6\n",
            "          44       1.00      0.80      0.89         5\n",
            "          45       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.77      2246\n",
            "   macro avg       0.69      0.57      0.59      2246\n",
            "weighted avg       0.77      0.77      0.77      2246\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결정 트리(Decision Tree)"
      ],
      "metadata": {
        "id": "A6oSxXufF-hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
        "tree.fit(tfidfv, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u9ACg8aF-Hh",
        "outputId": "0079fc70-3ad3-4677-fc19-a8a5cf727daa"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(max_depth=10, random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
        "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4s345QUOGG64",
        "outputId": "7c9337d7-63e5-4b27-9c0b-c983c9328dfc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.6179875333926982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, tree.predict(tfidfv_test), zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVw06z78HBQU",
        "outputId": "b7198e82-42d2-4dfd-8596-393eab90445d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        12\n",
            "           1       0.72      0.40      0.52       105\n",
            "           2       0.60      0.45      0.51        20\n",
            "           3       0.94      0.84      0.89       813\n",
            "           4       0.39      0.91      0.55       474\n",
            "           5       0.00      0.00      0.00         5\n",
            "           6       1.00      0.57      0.73        14\n",
            "           7       0.00      0.00      0.00         3\n",
            "           8       0.00      0.00      0.00        38\n",
            "           9       0.88      0.88      0.88        25\n",
            "          10       0.87      0.87      0.87        30\n",
            "          11       0.62      0.48      0.54        83\n",
            "          12       0.17      0.08      0.11        13\n",
            "          13       0.00      0.00      0.00        37\n",
            "          14       0.00      0.00      0.00         2\n",
            "          15       0.00      0.00      0.00         9\n",
            "          16       0.60      0.82      0.69        99\n",
            "          17       0.00      0.00      0.00        12\n",
            "          18       0.00      0.00      0.00        20\n",
            "          19       0.62      0.26      0.37       133\n",
            "          20       0.33      0.03      0.05        70\n",
            "          21       0.00      0.00      0.00        27\n",
            "          22       0.00      0.00      0.00         7\n",
            "          23       0.00      0.00      0.00        12\n",
            "          24       1.00      0.05      0.10        19\n",
            "          25       0.86      0.19      0.32        31\n",
            "          26       0.00      0.00      0.00         8\n",
            "          27       0.00      0.00      0.00         4\n",
            "          28       0.50      0.10      0.17        10\n",
            "          29       0.00      0.00      0.00         4\n",
            "          30       0.00      0.00      0.00        12\n",
            "          31       0.00      0.00      0.00        13\n",
            "          32       0.00      0.00      0.00        10\n",
            "          33       0.83      1.00      0.91         5\n",
            "          34       0.00      0.00      0.00         7\n",
            "          35       0.00      0.00      0.00         6\n",
            "          36       0.00      0.00      0.00        11\n",
            "          37       0.00      0.00      0.00         2\n",
            "          38       0.00      0.00      0.00         3\n",
            "          39       0.00      0.00      0.00         5\n",
            "          40       0.00      0.00      0.00        10\n",
            "          41       0.00      0.00      0.00         8\n",
            "          42       0.00      0.00      0.00         3\n",
            "          43       0.00      0.00      0.00         6\n",
            "          44       0.00      0.00      0.00         5\n",
            "          45       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.62      2246\n",
            "   macro avg       0.24      0.17      0.18      2246\n",
            "weighted avg       0.61      0.62      0.57      2246\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "랜덤 포레스트(Random Forest)"
      ],
      "metadata": {
        "id": "6c2cAenTGOU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
        "forest.fit(tfidfv, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etTOJ417GNzX",
        "outputId": "bc03aee0-afdf-41eb-cc62-39bac7804ea4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=5, random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
        "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVcRc1bHGS3M",
        "outputId": "5feb7133-bdab-4fd0-deaf-b1a8de37f084"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.701246660730187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, forest.predict(tfidfv_test), zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfdFTx-9GYVb",
        "outputId": "b0b49845-5781-4e4f-c288-aec4e684af03"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      0.42      0.33        12\n",
            "           1       0.42      0.78      0.55       105\n",
            "           2       0.44      0.35      0.39        20\n",
            "           3       0.84      0.90      0.87       813\n",
            "           4       0.68      0.84      0.75       474\n",
            "           5       0.00      0.00      0.00         5\n",
            "           6       0.86      0.43      0.57        14\n",
            "           7       1.00      0.33      0.50         3\n",
            "           8       0.59      0.53      0.56        38\n",
            "           9       0.71      0.40      0.51        25\n",
            "          10       0.89      0.53      0.67        30\n",
            "          11       0.57      0.69      0.62        83\n",
            "          12       0.33      0.15      0.21        13\n",
            "          13       0.46      0.32      0.38        37\n",
            "          14       0.00      0.00      0.00         2\n",
            "          15       1.00      0.11      0.20         9\n",
            "          16       0.70      0.67      0.68        99\n",
            "          17       0.00      0.00      0.00        12\n",
            "          18       0.60      0.45      0.51        20\n",
            "          19       0.62      0.64      0.63       133\n",
            "          20       0.46      0.33      0.38        70\n",
            "          21       0.65      0.41      0.50        27\n",
            "          22       0.00      0.00      0.00         7\n",
            "          23       0.75      0.25      0.38        12\n",
            "          24       0.33      0.05      0.09        19\n",
            "          25       0.87      0.42      0.57        31\n",
            "          26       1.00      0.12      0.22         8\n",
            "          27       1.00      0.25      0.40         4\n",
            "          28       0.00      0.00      0.00        10\n",
            "          29       0.33      0.25      0.29         4\n",
            "          30       0.00      0.00      0.00        12\n",
            "          31       0.00      0.00      0.00        13\n",
            "          32       1.00      0.30      0.46        10\n",
            "          33       1.00      0.20      0.33         5\n",
            "          34       0.00      0.00      0.00         7\n",
            "          35       1.00      0.17      0.29         6\n",
            "          36       0.33      0.09      0.14        11\n",
            "          37       1.00      0.50      0.67         2\n",
            "          38       0.00      0.00      0.00         3\n",
            "          39       0.00      0.00      0.00         5\n",
            "          40       1.00      0.20      0.33        10\n",
            "          41       0.25      0.12      0.17         8\n",
            "          42       0.00      0.00      0.00         3\n",
            "          43       1.00      0.33      0.50         6\n",
            "          44       1.00      0.80      0.89         5\n",
            "          45       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.70      2246\n",
            "   macro avg       0.54      0.31      0.36      2246\n",
            "weighted avg       0.69      0.70      0.68      2246\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그래디언트 부스팅 트리(GradientBoostingClassifier)"
      ],
      "metadata": {
        "id": "TVtcZlhMHsy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
        "grbt.fit(tfidfv, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SsfE0NCGozm",
        "outputId": "eb71a210-cfc7-49a1-c907-efdc39a01f1a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
        "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZctvnEaHw9A",
        "outputId": "58fc6534-2193-43c0-f32f-b20e768e0fc5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.767586821015138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, grbt.predict(tfidfv_test), zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL8bbcPHH63R",
        "outputId": "6cab6421-2028-45f6-ecb5-3da5fad40d10"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.67      0.76        12\n",
            "           1       0.80      0.68      0.73       105\n",
            "           2       0.70      0.70      0.70        20\n",
            "           3       0.90      0.90      0.90       813\n",
            "           4       0.76      0.83      0.79       474\n",
            "           5       0.14      0.20      0.17         5\n",
            "           6       0.93      0.93      0.93        14\n",
            "           7       0.50      0.33      0.40         3\n",
            "           8       0.64      0.66      0.65        38\n",
            "           9       0.91      0.84      0.87        25\n",
            "          10       0.87      0.87      0.87        30\n",
            "          11       0.62      0.66      0.64        83\n",
            "          12       0.46      0.46      0.46        13\n",
            "          13       0.55      0.43      0.48        37\n",
            "          14       0.08      0.50      0.14         2\n",
            "          15       0.33      0.22      0.27         9\n",
            "          16       0.72      0.77      0.75        99\n",
            "          17       0.33      0.33      0.33        12\n",
            "          18       0.61      0.55      0.58        20\n",
            "          19       0.71      0.65      0.68       133\n",
            "          20       0.56      0.44      0.50        70\n",
            "          21       0.67      0.67      0.67        27\n",
            "          22       0.50      0.14      0.22         7\n",
            "          23       0.36      0.42      0.38        12\n",
            "          24       0.71      0.63      0.67        19\n",
            "          25       0.91      0.65      0.75        31\n",
            "          26       0.75      0.75      0.75         8\n",
            "          27       0.40      0.50      0.44         4\n",
            "          28       0.38      0.30      0.33        10\n",
            "          29       0.22      0.50      0.31         4\n",
            "          30       0.38      0.42      0.40        12\n",
            "          31       0.60      0.46      0.52        13\n",
            "          32       0.88      0.70      0.78        10\n",
            "          33       0.71      1.00      0.83         5\n",
            "          34       0.50      0.29      0.36         7\n",
            "          35       1.00      0.50      0.67         6\n",
            "          36       0.67      0.55      0.60        11\n",
            "          37       0.67      1.00      0.80         2\n",
            "          38       0.25      0.33      0.29         3\n",
            "          39       0.25      0.20      0.22         5\n",
            "          40       0.71      0.50      0.59        10\n",
            "          41       0.44      0.50      0.47         8\n",
            "          42       0.75      1.00      0.86         3\n",
            "          43       0.50      0.67      0.57         6\n",
            "          44       1.00      0.80      0.89         5\n",
            "          45       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.77      2246\n",
            "   macro avg       0.60      0.59      0.58      2246\n",
            "weighted avg       0.77      0.77      0.77      2246\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "보팅 "
      ],
      "metadata": {
        "id": "zCO1iwgJRbot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "voting_classifier = VotingClassifier(estimators=[\n",
        "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
        "        ('cb', ComplementNB()),\n",
        "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
        "], voting='soft', n_jobs=-1)\n",
        "voting_classifier.fit(tfidfv, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd9OQ9YsReiX",
        "outputId": "f455eb13-f334-4256-e473-7871918619e1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('lr', LogisticRegression(C=10000)),\n",
              "                             ('cb', ComplementNB()),\n",
              "                             ('grbt',\n",
              "                              GradientBoostingClassifier(random_state=0))],\n",
              "                 n_jobs=-1, voting='soft')"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
        "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMZXwTqJRjIS",
        "outputId": "cefaa780-f282-4b24-a3f3-48edf3225e86"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.8161175422974176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, voting_classifier.predict(tfidfv_test), zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_SzdUKhRv4X",
        "outputId": "1c4e86d4-d6d3-4a2e-beb8-cad4b0db6525"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.75      0.82        12\n",
            "           1       0.80      0.77      0.79       105\n",
            "           2       0.71      0.85      0.77        20\n",
            "           3       0.92      0.94      0.93       813\n",
            "           4       0.82      0.88      0.85       474\n",
            "           5       0.33      0.20      0.25         5\n",
            "           6       0.93      0.93      0.93        14\n",
            "           7       0.67      0.67      0.67         3\n",
            "           8       0.72      0.68      0.70        38\n",
            "           9       0.81      0.84      0.82        25\n",
            "          10       0.93      0.90      0.92        30\n",
            "          11       0.67      0.70      0.68        83\n",
            "          12       0.60      0.46      0.52        13\n",
            "          13       0.68      0.62      0.65        37\n",
            "          14       0.12      0.50      0.20         2\n",
            "          15       0.67      0.44      0.53         9\n",
            "          16       0.74      0.74      0.74        99\n",
            "          17       0.57      0.67      0.62        12\n",
            "          18       0.72      0.65      0.68        20\n",
            "          19       0.73      0.68      0.71       133\n",
            "          20       0.61      0.49      0.54        70\n",
            "          21       0.66      0.78      0.71        27\n",
            "          22       0.50      0.14      0.22         7\n",
            "          23       0.57      0.67      0.62        12\n",
            "          24       0.75      0.63      0.69        19\n",
            "          25       0.96      0.74      0.84        31\n",
            "          26       0.88      0.88      0.88         8\n",
            "          27       0.67      0.50      0.57         4\n",
            "          28       0.44      0.40      0.42        10\n",
            "          29       0.50      0.75      0.60         4\n",
            "          30       0.62      0.42      0.50        12\n",
            "          31       0.75      0.69      0.72        13\n",
            "          32       1.00      0.80      0.89        10\n",
            "          33       0.71      1.00      0.83         5\n",
            "          34       1.00      0.43      0.60         7\n",
            "          35       1.00      0.50      0.67         6\n",
            "          36       0.45      0.45      0.45        11\n",
            "          37       0.67      1.00      0.80         2\n",
            "          38       0.50      0.33      0.40         3\n",
            "          39       0.25      0.20      0.22         5\n",
            "          40       0.80      0.40      0.53        10\n",
            "          41       0.67      0.50      0.57         8\n",
            "          42       0.75      1.00      0.86         3\n",
            "          43       0.71      0.83      0.77         6\n",
            "          44       1.00      0.80      0.89         5\n",
            "          45       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.82      2246\n",
            "   macro avg       0.71      0.66      0.66      2246\n",
            "weighted avg       0.82      0.82      0.81      2246\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "딥러닝 모델과 비교해 보기"
      ],
      "metadata": {
        "id": "Vh1HxREzZq-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=5000, test_split=0.2)"
      ],
      "metadata": {
        "id": "BSY8Rd6tb5W1"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "max_len=145\n",
        "X_train = pad_sequences(x_train, maxlen=max_len)\n",
        "X_test = pad_sequences(x_test, maxlen=max_len)\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "cm36LXfzfrs1"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "vocab_size = 5000 #사용할 단어사전 크기\n",
        "embedding_dim = 128 #임베딩레이어 차원 수 \n",
        "\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(vocab_size, embedding_dim))\n",
        "model.add(tf.keras.layers.LSTM(128)) #hidden 노드 128개\n",
        "model.add(tf.keras.layers.Dense(46, activation='softmax')) \n",
        "\n",
        "\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvATtjnCfuml",
        "outputId": "b33406b6-ccb4-4ef8-a577-42b3c4c2f60f"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, None, 128)         640000    \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 46)                5934      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 777,518\n",
            "Trainable params: 777,518\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "epochs=100  \n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)  \n",
        "mc = ModelCheckpoint('best', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
        "\n",
        "history = model.fit(X_train, \n",
        "                    y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=512,\n",
        "                    callbacks=(es,mc),\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cnzf6C4Vf0bQ",
        "outputId": "47497be0-e9fd-4746-e848-b8341608eb01"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.8549 - accuracy: 0.7761\n",
            "Epoch 1: val_loss improved from inf to 1.54194, saving model to best\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7feaccd83a10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 29s 2s/step - loss: 0.8549 - accuracy: 0.7761 - val_loss: 1.5419 - val_accuracy: 0.6427\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.7433 - accuracy: 0.8032\n",
            "Epoch 2: val_loss did not improve from 1.54194\n",
            "15/15 [==============================] - 22s 1s/step - loss: 0.7433 - accuracy: 0.8032 - val_loss: 1.5691 - val_accuracy: 0.6344\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.7428 - accuracy: 0.8056\n",
            "Epoch 3: val_loss did not improve from 1.54194\n",
            "15/15 [==============================] - 22s 1s/step - loss: 0.7428 - accuracy: 0.8056 - val_loss: 1.5480 - val_accuracy: 0.6433\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6862 - accuracy: 0.8267\n",
            "Epoch 4: val_loss improved from 1.54194 to 1.52890, saving model to best\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7feaccd83a10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 26s 2s/step - loss: 0.6862 - accuracy: 0.8267 - val_loss: 1.5289 - val_accuracy: 0.6578\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6386 - accuracy: 0.8386\n",
            "Epoch 5: val_loss improved from 1.52890 to 1.52801, saving model to best\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7feaccd83a10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 26s 2s/step - loss: 0.6386 - accuracy: 0.8386 - val_loss: 1.5280 - val_accuracy: 0.6539\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6185 - accuracy: 0.8420\n",
            "Epoch 6: val_loss did not improve from 1.52801\n",
            "15/15 [==============================] - 22s 1s/step - loss: 0.6185 - accuracy: 0.8420 - val_loss: 1.5577 - val_accuracy: 0.6522\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5945 - accuracy: 0.8469\n",
            "Epoch 7: val_loss did not improve from 1.52801\n",
            "15/15 [==============================] - 22s 1s/step - loss: 0.5945 - accuracy: 0.8469 - val_loss: 1.6082 - val_accuracy: 0.6539\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5570 - accuracy: 0.8558\n",
            "Epoch 8: val_loss did not improve from 1.52801\n",
            "15/15 [==============================] - 22s 1s/step - loss: 0.5570 - accuracy: 0.8558 - val_loss: 1.5900 - val_accuracy: 0.6433\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5331 - accuracy: 0.8601\n",
            "Epoch 9: val_loss did not improve from 1.52801\n",
            "15/15 [==============================] - 22s 1s/step - loss: 0.5331 - accuracy: 0.8601 - val_loss: 1.6257 - val_accuracy: 0.6411\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5328 - accuracy: 0.8621\n",
            "Epoch 10: val_loss did not improve from 1.52801\n",
            "15/15 [==============================] - 22s 1s/step - loss: 0.5328 - accuracy: 0.8621 - val_loss: 1.6143 - val_accuracy: 0.6555\n",
            "Epoch 10: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\"는 \"파란색 점\"입니다\n",
        "plt.plot(epochs, acc, 'red', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'green', label='Validation acc')\n",
        "plt.plot(epochs, loss, 'purple', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'blue', label='Validation loss')\n",
        "# b는 \"파란 실선\"입니다\n",
        "\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "AzdQx4gwoGJd",
        "outputId": "ee32a73b-b935-4ead-9487-449314c4ff94"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** 회고록\n",
        "\n",
        "\n",
        "머신 러닝에서 보팅이 가장 정확도가 높아서 보팅이 성능이 좋은 것으로 보인다. 딥러닝은 이전 익스에서 했던 것을 참고로 해서 작성을 하였다. LSTM이 보팅보다 성능이 조금 더 좋은 것으로 확인이 되었다. 고잉디퍼로 넘어가면서 이론이 많이 어려운데 그래도 노드를 참고해서 하다보니 코드 작성에 크게 어려움은 없었다. "
      ],
      "metadata": {
        "id": "HO_91TnNoXkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uSYm426saiAw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}