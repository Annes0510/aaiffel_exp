{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10-5. 프로젝트: 더 멋진 번역기 만들기.Going Deeper(NLP)_YJ2",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1k4zrIcCOnmRTy73Gl4SGdy1Gv0B9q4lJ",
      "authorship_tag": "ABX9TyPu6yVXg9/zeKqSdcOXOMPG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Annes0510/aaiffel_exp/blob/mian/10_5_%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8_%EB%8D%94_%EB%A9%8B%EC%A7%84_%EB%B2%88%EC%97%AD%EA%B8%B0_%EB%A7%8C%EB%93%A4%EA%B8%B0_Going_Deeper(NLP)_YJ2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10-1. 들어가며"
      ],
      "metadata": {
        "id": "GKPAWJRKjJka"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVuuz5ZLhjcJ",
        "outputId": "c679415e-a8bd-4ca6-f539-2e6cc0c1c0cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 9,604 kB of archives.\n",
            "After this operation, 29.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-nanum all 20170925-1 [9,604 kB]\n",
            "Fetched 9,604 kB in 0s (23.8 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 155455 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20170925-1_all.deb ...\n",
            "Unpacking fonts-nanum (20170925-1) ...\n",
            "Setting up fonts-nanum (20170925-1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        " \n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "mpl.font_manager.findfont(font)\n",
        "\n",
        "print(\"슝=3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G8uTFOijn5e",
        "outputId": "517b8877-56dc-42df-d818-2ccbe5bd9ae4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10-2. 내부 모듈 구현하기"
      ],
      "metadata": {
        "id": "1PzSX4ihjslA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflow==2.6.0\n",
        "#!pip install keras==2.6.0"
      ],
      "metadata": {
        "id": "PC04m_UXjtH2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import re\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import random\n",
        "\n",
        "import seaborn # Attention 시각화를 위해 필요!\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt5-1lxgkKzZ",
        "outputId": "15565192-187c-4cdf-9aab-ef074c195886"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "metadata": {
        "id": "rbtWtW0Dxmb8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Positional Encoding"
      ],
      "metadata": {
        "id": "7rzQjDLkkTEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(pos, d_model):\n",
        "    def cal_angle(position, i):\n",
        "        return position / np.power(10000, int(i) / d_model)\n",
        "\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, i) for i in range(d_model)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
        "    return sinusoid_table\n",
        "\n",
        "print(\"슝=3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUJA0L_akVew",
        "outputId": "866fc017-04fe-4f30-b65f-4ccc1f94953d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "            \n",
        "        self.depth = d_model // self.num_heads\n",
        "            \n",
        "        self.W_q = tf.keras.layers.Dense(d_model)\n",
        "        self.W_k = tf.keras.layers.Dense(d_model)\n",
        "        self.W_v = tf.keras.layers.Dense(d_model)\n",
        "            \n",
        "        self.linear = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
        "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
        "        QK = tf.matmul(Q, K, transpose_b=True)\n",
        "\n",
        "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
        "\n",
        "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
        "\n",
        "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
        "        out = tf.matmul(attentions, V)\n",
        "\n",
        "        return out, attentions\n",
        "            \n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        split_x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
        "\n",
        "        return split_x\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "        combined_x = tf.reshape(combined_x, (batch_size, -1, self.d_model))\n",
        "\n",
        "        return combined_x\n",
        "\n",
        "        \n",
        "    def call(self, Q, K, V, mask):\n",
        "        WQ = self.W_q(Q)\n",
        "        WK = self.W_k(K)\n",
        "        WV = self.W_v(V)\n",
        "        \n",
        "        WQ_splits = self.split_heads(WQ)\n",
        "        WK_splits = self.split_heads(WK)\n",
        "        WV_splits = self.split_heads(WV)\n",
        "            \n",
        "        out, attention_weights = self.scaled_dot_product_attention(\n",
        "            WQ_splits, WK_splits, WV_splits, mask)\n",
        "    \t\t\t\t        \n",
        "        out = self.combine_heads(out)\n",
        "        out = self.linear(out)\n",
        "                \n",
        "        return out, attention_weights"
      ],
      "metadata": {
        "id": "TtZD8r6lk4gO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Position-wise Feed-Forward Network"
      ],
      "metadata": {
        "id": "MrjBMyp5k-DT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PoswiseFeedForwardNet, self).__init__()\n",
        "        self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
        "        self.w_2 = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def call(self, x):\n",
        "        out = self.w_1(x)\n",
        "        out = self.w_2(out)\n",
        "            \n",
        "        return out\n",
        "\n",
        "print(\"슝=3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzusHzVWk6R3",
        "outputId": "e5f94e66-b255-412f-e738-23d74f5dc3cf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10-3. 모듈 조립하기"
      ],
      "metadata": {
        "id": "7qw4ZZpTlDHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder 레이어 구현하기\n"
      ],
      "metadata": {
        "id": "wR8OgSrjlFr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
        "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
        "\n",
        "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "        \n",
        "    def call(self, x, mask):\n",
        "\n",
        "        \"\"\"\n",
        "        Multi-Head Attention\n",
        "        \"\"\"\n",
        "        residual = x\n",
        "        out = self.norm_1(x)\n",
        "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "        \n",
        "        \"\"\"\n",
        "        Position-Wise Feed Forward Network\n",
        "        \"\"\"\n",
        "        residual = out\n",
        "        out = self.norm_2(out)\n",
        "        out = self.ffn(out)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "        \n",
        "        return out, enc_attn\n",
        "\n",
        "print(\"슝=3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBeTcq8plHgH",
        "outputId": "371942ad-93a4-444f-a67f-0451338f03b7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoder 레이어 구현하기"
      ],
      "metadata": {
        "id": "hgLzSAX0lKrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
        "\n",
        "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "    \n",
        "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
        "\n",
        "        \"\"\"\n",
        "        Masked Multi-Head Attention\n",
        "        \"\"\"\n",
        "        residual = x\n",
        "        out = self.norm_1(x)\n",
        "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "\n",
        "        \"\"\"\n",
        "        Multi-Head Attention\n",
        "        \"\"\"\n",
        "        residual = out\n",
        "        out = self.norm_2(out)\n",
        "        out, dec_enc_attn = self.enc_dec_attn(out, enc_out, enc_out, causality_mask)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "        \n",
        "        \"\"\"\n",
        "        Position-Wise Feed Forward Network\n",
        "        \"\"\"\n",
        "        residual = out\n",
        "        out = self.norm_3(out)\n",
        "        out = self.ffn(out)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "\n",
        "        return out, dec_attn, dec_enc_attn"
      ],
      "metadata": {
        "id": "-vRbbXnFlLQW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 d_model,\n",
        "                 n_heads,\n",
        "                 d_ff,\n",
        "                 dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
        "                            for _ in range(n_layers)]\n",
        "                            \n",
        "                            \n",
        "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
        "        out = x\n",
        "    \n",
        "        dec_attns = list()\n",
        "        dec_enc_attns = list()\n",
        "        for i in range(self.n_layers):\n",
        "            out, dec_attn, dec_enc_attn = \\\n",
        "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
        "\n",
        "            dec_attns.append(dec_attn)\n",
        "            dec_enc_attns.append(dec_enc_attn)\n",
        "\n",
        "        return out, dec_attns, dec_enc_attns\n",
        "\n",
        "print(\"슝=3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa3kdTnIlVyI",
        "outputId": "e5931bc2-1601-497a-a7d4-74246560092f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer 완성하기"
      ],
      "metadata": {
        "id": "1s06oD2ClY3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                    n_layers,\n",
        "                    d_model,\n",
        "                    n_heads,\n",
        "                    d_ff,\n",
        "                    src_vocab_size,\n",
        "                    tgt_vocab_size,\n",
        "                    pos_len,\n",
        "                    dropout=0.2,\n",
        "                    shared=True):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.d_model = tf.cast(d_model, tf.float32)\n",
        "\n",
        "        self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
        "        self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
        "\n",
        "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
        "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
        "\n",
        "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
        "\n",
        "        self.shared = shared\n",
        "\n",
        "        if shared: self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
        "\n",
        "    def embedding(self, emb, x):\n",
        "        seq_len = x.shape[1]\n",
        "        out = emb(x)\n",
        "\n",
        "        if self.shared: out *= tf.math.sqrt(self.d_model)\n",
        "\n",
        "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "        \n",
        "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
        "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
        "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
        "\n",
        "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
        "        \n",
        "        dec_out, dec_attns, dec_enc_attns = \\\n",
        "        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
        "        \n",
        "        logits = self.fc(dec_out)\n",
        "        \n",
        "        return logits, enc_attns, dec_attns, dec_enc_attns"
      ],
      "metadata": {
        "id": "ZKitnFhkldRz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10-4. 모델 밖의 조력자들"
      ],
      "metadata": {
        "id": "z9xfL4hlltmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def generate_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "def generate_causality_mask(src_len, tgt_len):\n",
        "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
        "    return tf.cast(mask, tf.float32)\n",
        "\n",
        "def generate_masks(src, tgt):\n",
        "    enc_mask = generate_padding_mask(src)\n",
        "    dec_mask = generate_padding_mask(tgt)\n",
        "\n",
        "    dec_enc_causality_mask = generate_causality_mask(tgt.shape[1], src.shape[1])\n",
        "    dec_enc_mask = tf.maximum(enc_mask, dec_enc_causality_mask)\n",
        "\n",
        "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
        "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
        "\n",
        "    return enc_mask, dec_enc_mask, dec_mask\n",
        "\n",
        "print(\"슝=3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTACX3gVlutZ",
        "outputId": "93e6c085-944a-40d5-c3cb-ba36f29266c3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch, length = 16, 20\n",
        "src_padding = 5\n",
        "tgt_padding = 15\n",
        "\n",
        "src_pad = tf.zeros(shape=(batch, src_padding))\n",
        "tgt_pad = tf.zeros(shape=(batch, tgt_padding))\n",
        "\n",
        "sample_data = tf.ones(shape=(batch, length))\n",
        "\n",
        "sample_src = tf.concat([sample_data, src_pad], axis=-1)\n",
        "sample_tgt = tf.concat([sample_data, tgt_pad], axis=-1)\n",
        "\n",
        "enc_mask, dec_enc_mask, dec_mask = \\\n",
        "generate_masks(sample_src, sample_tgt)\n",
        "\n",
        "fig = plt.figure(figsize=(7, 7))\n",
        "\n",
        "ax1 = fig.add_subplot(131)\n",
        "ax2 = fig.add_subplot(132)\n",
        "ax3 = fig.add_subplot(133)\n",
        "\n",
        "ax1.set_title('1) Encoder Mask')\n",
        "ax2.set_title('2) Encoder-Decoder Mask')\n",
        "ax3.set_title('3) Decoder Mask')\n",
        "\n",
        "ax1.imshow(enc_mask[:3, 0, 0].numpy(), cmap='Dark2')\n",
        "ax2.imshow(dec_enc_mask[0, 0].numpy(), cmap='Dark2')\n",
        "ax3.imshow(dec_mask[0, 0].numpy(), cmap='Dark2')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "N0_kCn7ily4U",
        "outputId": "20ee6294-a117-4e1f-926c-358eb29ed23a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "findfont: Font family ['NanumBarunGothic'] not found. Falling back to DejaVu Sans.\n",
            "findfont: Font family ['NanumBarunGothic'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x504 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 428,
              "height": 207
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(LearningRateScheduler, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.warmup_steps = warmup_steps\n",
        "    \n",
        "    def __call__(self, step):\n",
        "        arg1 = step ** -0.5\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "        \n",
        "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "learning_rate = LearningRateScheduler(512)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
        "                                     beta_1=0.9,\n",
        "                                     beta_2=0.98, \n",
        "                                     epsilon=1e-9)\n",
        "\n",
        "print(\"슝=3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48qqcC-Pl2ig",
        "outputId": "1efbd02a-a0b8-4ab8-e710-16483af3dac1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10-5. 프로젝트: 더 멋진 번역기 만들기"
      ],
      "metadata": {
        "id": "sp07wv55l9g2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfY5KbLJm-ES",
        "outputId": "af3ee95a-f04d-4f07-f9bb-ef45074371b4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "import numpy\n",
        "import matplotlib\n",
        "\n",
        "print(tensorflow.__version__)\n",
        "print(numpy.__version__)\n",
        "print(matplotlib.__version__)"
      ],
      "metadata": {
        "id": "uqbRa4n5l_j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1. 데이터 다운로드 (클라우드 유저용)\n",
        "\n",
        "https://raw.githubusercontent.com/jungyeul/korean-parallel-corpora/master/korean-english-news-v1/korean-english-park.train.tar.gz"
      ],
      "metadata": {
        "id": "gUgpxuZnmJgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7iYiSv-mQMM",
        "outputId": "9145353b-e0cf-4bf1-d7f8-a1871ce3327e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM037c9zn9zN",
        "outputId": "9a279b39-e2f1-41ba-e267-c435d95535e6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/jungyeul/korean-parallel-corpora/master/korean-english-news-v1/korean-english-park.train.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A2fZ4xFoBcd",
        "outputId": "4d362c55-cb62-4ebc-818d-e2c6e5032e12"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-12 12:41:08--  https://raw.githubusercontent.com/jungyeul/korean-parallel-corpora/master/korean-english-news-v1/korean-english-park.train.tar.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8718893 (8.3M) [application/octet-stream]\n",
            "Saving to: ‘korean-english-park.train.tar.gz.5’\n",
            "\n",
            "korean-english-park 100%[===================>]   8.31M  51.2MB/s    in 0.2s    \n",
            "\n",
            "2022-04-12 12:41:08 (51.2 MB/s) - ‘korean-english-park.train.tar.gz.5’ saved [8718893/8718893]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzvf korean-english-park.train.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95Ra0kVjp2B0",
        "outputId": "068d207f-9442-4d46-f4a8-2d17e7eca54b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "korean-english-park.train.en\n",
            "korean-english-park.train.ko\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive'\n",
        "kor_path = data_dir+\"/korean-english-park.train.ko\"\n",
        "eng_path = data_dir+\"/korean-english-park.train.en\"\n",
        "\n",
        "\n",
        "\n",
        "# 데이터 정제 및 토큰화\n",
        "def clean_corpus(kor_path, eng_path):\n",
        "    with open(kor_path, \"r\") as f: kor = f.read().splitlines()\n",
        "    with open(eng_path, \"r\") as f: eng = f.read().splitlines()\n",
        "    assert len(kor) == len(eng)\n",
        "\n",
        "    # [[YOUR CODE]]\n",
        "    cleaned_corpus = []\n",
        "    for pair in zip(kor, eng) : \n",
        "        cleaned_corpus.append(pair)\n",
        "\n",
        "    return list(set(cleaned_corpus))\n",
        "\n",
        "cleaned_corpus = clean_corpus(kor_path, eng_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "BWqJPH14p7Yz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_corpus[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67pPkdNMuX2z",
        "outputId": "e0a3a5de-3d92-4cdf-a280-661e5e08eef6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('이성태 한국은행 총재와 여섯 명의 정책 입안자들은 1일 은행간 대출에 부과되는 이자율인 콜금리의 12월 목표를 5퍼센트로 유지하기로 했다.',\n",
              " 'Lee Seong-tae and his six fellow policymakers held the December target for the call rate, the interest charged on overnight inter-bank loans, steady at a six-year high of 5 percent.')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "정제 함수를 아래 조건을 만족하게 정의하세요.\n",
        "\n",
        "1.   모든 입력을 소문자로 변환합니다.\n",
        "2.   알파벳, 문장부호, 한글만 남기고 모두 제거합니다.\n",
        "3.   문장부호 양옆에 공백을 추가합니다.\n",
        "4.   문장 앞뒤의 불필요한 공백을 제거합니다."
      ],
      "metadata": {
        "id": "3Giab5-dvK21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    \n",
        "    sentence = sentence.lower()\n",
        "    sentence = re.sub(r\"[^0-9가-힣a-zA-Z?.!,]+\", \" \", sentence)\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    \n",
        "    return sentence"
      ],
      "metadata": {
        "id": "nUlY1nmeveK6"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "단어 사전을 매개변수로 받아 원하는 크기의 사전을 정의할 수 있게 합니다. (기본: 20,000)\n",
        "\n",
        "        학습 후 저장된 model 파일을 SentencePieceProcessor() 클래스에 Load()한 후 반환합니다.\n",
        "\n",
        "        \n",
        "        특수 토큰의 인덱스를 아래와 동일하게 지정합니다.\n",
        "        <PAD> : 0 / <BOS> : 1 / <EOS> : 2 / <UNK> : 3"
      ],
      "metadata": {
        "id": "hV8bcbsmwnR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZyXJNcBo8yM",
        "outputId": "da37c5cf-1c39-4ffd-896e-28ef89b32244"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm"
      ],
      "metadata": {
        "id": "_RQzxyvbeUvD"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_tokenizer(corpus,\n",
        "                        vocab_size,\n",
        "                        lang=\"ko\",\n",
        "                        pad_id=0,\n",
        "                        bos_id=1,\n",
        "                        eos_id=2,\n",
        "                        unk_id=3):\n",
        "    # [[YOUR CODE]]\n",
        "    model_prefix = 'spm_'+lang\n",
        "    spm.SentencePieceTrainer.Train( # unigram model \n",
        "        '--input={} --model_prefix={} --vocab_size={} \\\n",
        "        --pad_id={} --bos_id={} --eos_id={} --unk_id={}'.format(corpus, model_prefix, vocab_size, pad_id, bos_id, eos_id, unk_id)    \n",
        "    ) \n",
        "    \n",
        "    tokenizer = spm.SentencePieceProcessor()\n",
        "    tokenizer.Load(model_prefix+'.model')\n",
        "    \n",
        "    return tokenizer\n",
        "\n",
        "!ls -l korean_spm*"
      ],
      "metadata": {
        "id": "ZeJ8ojyFwiE0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a676cbe-ec8c-48ad-85e0-96e58162d926"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'korean_spm*': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_VOCAB_SIZE = TGT_VOCAB_SIZE = 20000\n",
        "\n",
        "eng_corpus = []\n",
        "kor_corpus = []\n",
        "\n",
        "for pair in cleaned_corpus:\n",
        "    k = pair[0]\n",
        "    e = pair[1]\n",
        "\n",
        "    kor_corpus.append(preprocess_sentence(k))\n",
        "    eng_corpus.append(preprocess_sentence(e))"
      ],
      "metadata": {
        "id": "f03925eeBrae"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kor_corpus[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GEsC-mtBva6",
        "outputId": "7317d6b6-3073-4e41-d18d-a64c54e204fd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['양측은 세계 최대 미개발 유전 지역인 아자데간 유전 개발에 대한 최종 협상을 2주 안에 마무리 지을 것이라고 말했다 .',\n",
              " '홍콩 보건 관리들은 일요일 , 지난 26일 괴질에 걸린 한 남성이 베이징 발 홍콩행 드래건에어 ka901편에 탑승했었으며 , 당국은 다른 탑승객 222명과 승무원 15명의 감염여부를 파악하기 위해 추적하려고 한다고 말했다 .',\n",
              " '미국 프로풋볼 nfl 애틀랜타 팰컨스 소속의 마이클 빅이 투견 도박장에 사용될 핏불을 훈련시키는 사업에 관여 , 살인혐의를 받았다고 17일 현지시간 연방검찰이 밝혔다 .',\n",
              " '이성태 한국은행 총재와 여섯 명의 정책 입안자들은 1일 은행간 대출에 부과되는 이자율인 콜금리의 12월 목표를 5퍼센트로 유지하기로 했다 .',\n",
              " '그는 휴대폰 시장과 관련해 아이폰 iphone 이 2009년 추수감사절 전까지 블루투스 a2dp와 변하지 않는 배터리처럼 빠져있던 기능을 갖춘 신제품을 출시하면서 대세를 이어갈 것이며 동영상 녹화 기능을 갖춘 고해상도 카메라도 선보일 것 이라며 그러나 운명을 좌우하는 것은 애플이 다른 개발자의 어플리케이션과 얼마나 열려있느냐에 달려있다 고 덧붙였다 .']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(kor_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd692y5_Bxlz",
        "outputId": "5054c4bc-cfce-41a0-e359-8e4bfdca43a5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng_corpus[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_zHKSXWEUOK",
        "outputId": "82821431-08fb-405c-b674-6c5ad85b3193"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['both sides say they are less than two weeks away from final agreement over the azadegan field , which is one of the world s biggest untapped oil reserves .',\n",
              " 'hong kong health officials said sunday that a man who came down with the illness had been aboard dragonair flight ka901 from beijing hong kong on march 26 and they were trying to trace the other 222 passengers and 15 crew to see if they were infected .',\n",
              " 'atlanta falcons quarterback michael vick faces criminal charges and a possible prison sentence for allegedly participating in an enterprise that trained pit bulls for death matches in which spectators bet on the outcome , federal prosecutors announced tuesday .',\n",
              " 'lee seong tae and his six fellow policymakers held the december target for the call rate , the interest charged on overnight inter bank loans , steady at a six year high of 5 percent .',\n",
              " 'expect to see them coming in all sizes and probably with a multi touch feature by the end of the year .']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 50"
      ],
      "metadata": {
        "id": "NFx73JYM2iKL"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3. 모델 설계"
      ],
      "metadata": {
        "id": "T6KzQJmX0JpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(pos, d_model):\n",
        "    def cal_angle(position, i):\n",
        "        return position / np.power(10000, int(i) / d_model)\n",
        "\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, i) for i in range(d_model)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
        "    return sinusoid_table\n",
        "\n",
        "print(\"슝=3\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmsMcBTtEWNz",
        "outputId": "6b1dd597-ccbc-4687-b332-f50349849f0a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "            \n",
        "        self.depth = d_model // self.num_heads\n",
        "            \n",
        "        self.W_q = tf.keras.layers.Dense(d_model)\n",
        "        self.W_k = tf.keras.layers.Dense(d_model)\n",
        "        self.W_v = tf.keras.layers.Dense(d_model)\n",
        "            \n",
        "        self.linear = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
        "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
        "        QK = tf.matmul(Q, K, transpose_b=True)\n",
        "\n",
        "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
        "\n",
        "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
        "\n",
        "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
        "        out = tf.matmul(attentions, V)\n",
        "\n",
        "        return out, attentions\n",
        "            \n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        split_x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
        "\n",
        "        return split_x\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "        combined_x = tf.reshape(combined_x, (batch_size, -1, self.d_model))\n",
        "\n",
        "        return combined_x\n",
        "\n",
        "        \n",
        "    def call(self, Q, K, V, mask):\n",
        "        WQ = self.W_q(Q)\n",
        "        WK = self.W_k(K)\n",
        "        WV = self.W_v(V)\n",
        "        \n",
        "        WQ_splits = self.split_heads(WQ)\n",
        "        WK_splits = self.split_heads(WK)\n",
        "        WV_splits = self.split_heads(WV)\n",
        "            \n",
        "        out, attention_weights = self.scaled_dot_product_attention(\n",
        "            WQ_splits, WK_splits, WV_splits, mask)\n",
        "    \t\t\t\t        \n",
        "        out = self.combine_heads(out)\n",
        "        out = self.linear(out)\n",
        "                \n",
        "        return out, attention_weights"
      ],
      "metadata": {
        "id": "07F137nMzzzE"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PoswiseFeedForwardNet, self).__init__()\n",
        "        self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
        "        self.w_2 = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def call(self, x):\n",
        "        out = self.w_1(x)\n",
        "        out = self.w_2(out)\n",
        "            \n",
        "        return out\n",
        "\n",
        "print(\"슝=3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMHisMjwz22I",
        "outputId": "65f8cb8c-5e3a-46b6-8825-edc817b3ce44"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
        "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
        "\n",
        "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "        \n",
        "    def call(self, x, mask):\n",
        "\n",
        "        \"\"\"\n",
        "        Multi-Head Attention\n",
        "        \"\"\"\n",
        "        residual = x\n",
        "        out = self.norm_1(x)\n",
        "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "        \n",
        "        \"\"\"\n",
        "        Position-Wise Feed Forward Network\n",
        "        \"\"\"\n",
        "        residual = out\n",
        "        out = self.norm_2(out)\n",
        "        out = self.ffn(out)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "        \n",
        "        return out, enc_attn\n",
        "\n",
        "print(\"슝=3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5c3JT-Nz52T",
        "outputId": "6dd77319-a6bc-438b-a5dd-8eb020818bc0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
        "\n",
        "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "    \n",
        "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
        "\n",
        "        \"\"\"\n",
        "        Masked Multi-Head Attention\n",
        "        \"\"\"\n",
        "        residual = x\n",
        "        out = self.norm_1(x)\n",
        "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "\n",
        "        \"\"\"\n",
        "        Multi-Head Attention\n",
        "        \"\"\"\n",
        "        residual = out\n",
        "        out = self.norm_2(out)\n",
        "        out, dec_enc_attn = self.enc_dec_attn(out, enc_out, enc_out, causality_mask)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "        \n",
        "        \"\"\"\n",
        "        Position-Wise Feed Forward Network\n",
        "        \"\"\"\n",
        "        residual = out\n",
        "        out = self.norm_3(out)\n",
        "        out = self.ffn(out)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "\n",
        "        return out, dec_attn, dec_enc_attn"
      ],
      "metadata": {
        "id": "v8wSsqAfz9cA"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 d_model,\n",
        "                 n_heads,\n",
        "                 d_ff,\n",
        "                 dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
        "                        for _ in range(n_layers)]\n",
        "        \n",
        "    def call(self, x, mask):\n",
        "        out = x\n",
        "    \n",
        "        enc_attns = list()\n",
        "        for i in range(self.n_layers):\n",
        "            out, enc_attn = self.enc_layers[i](out, mask)\n",
        "            enc_attns.append(enc_attn)\n",
        "        \n",
        "        return out, enc_attns\n",
        "\n",
        "print(\"슝=3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_A5SAUU0U-8",
        "outputId": "ec18c100-16f9-4e6d-ac10-a02ccac412b6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 d_model,\n",
        "                 n_heads,\n",
        "                 d_ff,\n",
        "                 dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
        "                            for _ in range(n_layers)]\n",
        "                            \n",
        "                            \n",
        "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
        "        out = x\n",
        "    \n",
        "        dec_attns = list()\n",
        "        dec_enc_attns = list()\n",
        "        for i in range(self.n_layers):\n",
        "            out, dec_attn, dec_enc_attn = \\\n",
        "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
        "\n",
        "            dec_attns.append(dec_attn)\n",
        "            dec_enc_attns.append(dec_enc_attn)\n",
        "\n",
        "        return out, dec_attns, dec_enc_attns\n",
        "\n",
        "print(\"슝=3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdZhovHZ0Wa1",
        "outputId": "4005bd0c-19c2-4736-df6c-ef9f05ff27fe"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer 완성하기"
      ],
      "metadata": {
        "id": "KOtwtWAH0Y6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                    n_layers,\n",
        "                    d_model,\n",
        "                    n_heads,\n",
        "                    d_ff,\n",
        "                    src_vocab_size,\n",
        "                    tgt_vocab_size,\n",
        "                    pos_len,\n",
        "                    dropout=0.2,\n",
        "                    shared=True):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.d_model = tf.cast(d_model, tf.float32)\n",
        "\n",
        "        self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
        "        self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
        "\n",
        "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
        "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
        "\n",
        "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
        "\n",
        "        self.shared = shared\n",
        "\n",
        "        if shared: self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
        "\n",
        "    def embedding(self, emb, x):\n",
        "        seq_len = x.shape[1]\n",
        "        out = emb(x)\n",
        "\n",
        "        if self.shared: out *= tf.math.sqrt(self.d_model)\n",
        "\n",
        "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "        \n",
        "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
        "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
        "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
        "\n",
        "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
        "        \n",
        "        dec_out, dec_attns, dec_enc_attns = \\\n",
        "        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
        "        \n",
        "        logits = self.fc(dec_out)\n",
        "        \n",
        "        return logits, enc_attns, dec_attns, dec_enc_attns\n"
      ],
      "metadata": {
        "id": "d4vUEvLU0eRe"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4. 훈련하기"
      ],
      "metadata": {
        "id": "GtoZ8UH017Ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Transformer(n_layers=2,  # 인코더와 디코더의 층의 개수\n",
        "                          d_model=512, # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "                          n_heads=8,   # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "                          d_ff=2048,\n",
        "                          src_vocab_size=SRC_VOCAB_SIZE,\n",
        "                          tgt_vocab_size=TGT_VOCAB_SIZE,\n",
        "                          pos_len=max_len,\n",
        "                          dropout=0.3)"
      ],
      "metadata": {
        "id": "Pk5fZ5pN2T2E"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = LearningRateScheduler(512) \n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
        "                                     beta_1=0.9,\n",
        "                                     beta_2=0.98, \n",
        "                                     epsilon=1e-9)\n"
      ],
      "metadata": {
        "id": "1wrcSoEJ22hP"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    # Masking 되지 않은 입력의 개수로 Scaling하는 과정\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "H4zCd9t026d3"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Step 함수 정의\n",
        "\n",
        "@tf.function()\n",
        "def train_step(src, tgt, model, optimizer):\n",
        "    gold = tgt[:, 1:]\n",
        "        \n",
        "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
        "\n",
        "    # 계산된 loss에 tf.GradientTape()를 적용해 학습을 진행합니다.\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
        "        model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
        "        loss = loss_function(gold, predictions[:, :-1])\n",
        "\n",
        "    # 최종적으로 optimizer.apply_gradients()가 사용됩니다. \n",
        "    # [[YOUR CODE]]\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    \n",
        "    return loss, enc_attns, dec_attns, dec_enc_attns"
      ],
      "metadata": {
        "id": "AZKO-zuz3GsB"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습을 진행합니다.\n",
        "매 Epoch 마다 제시된 예문에 대한 번역을 생성하고, 멋진 번역이 생성되면 그때의 하이퍼파라미터와 생성된 번역을 제출하세요!"
      ],
      "metadata": {
        "id": "ZRFv3bJD3d9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 오바마는 대통령이다.\n",
        "2. 시민들은 도시 속에 산다.\n",
        "3. 커피는 필요 없다.\n",
        "4. 일곱 명의 사망자가 발생했다."
      ],
      "metadata": {
        "id": "CxleRk0E3gyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "f-66V6xC5XiP"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#회고록\n",
        "\n",
        "트랜스포머 어렵다. 다른 공부하느라 시간이 역부족했다.\n",
        "모델링까지는 노드를 보고 이어서 했지만, 학습하기에서 계속 에러가 나서 구글을 하고 찾아봤지만, 해결이 안돼었고, 어제부터 준비했지만 시간이 역부족했다. \n",
        "NLP 갈수록 어렵다...."
      ],
      "metadata": {
        "id": "euW0su_V_VdR"
      }
    }
  ]
}